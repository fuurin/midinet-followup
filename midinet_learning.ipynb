{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MidiNetモデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataLoaderの作成\n",
    "- Modelの作成\n",
    "- 学習コードの作成\n",
    "- 学習経過の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, ipdb, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from pypianoroll import Multitrack, Track\n",
    "from utils import grid_plot, Timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../datasets/theorytab/midinet\"\n",
    "input_file_path = f\"{base_dir}/midinet_natural.pkl\"\n",
    "output_dir = f\"{base_dir}/learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidinetDataloader():\n",
    "    def __init__(self, data_path):\n",
    "        data = pickle.load(open(data_path,'rb'))\n",
    "        \n",
    "        melody, prev, chord = [], [], []\n",
    "        for m, p, c in data:\n",
    "            melody.append(m)\n",
    "            prev.append(p)\n",
    "            chord.append(c)\n",
    "        \n",
    "        self.x = torch.from_numpy(np.array(melody)).float()\n",
    "        self.prev_x   = torch.from_numpy(np.array(prev)).float()\n",
    "        self.y  = torch.from_numpy(np.array(chord)).float()\n",
    "        self.size = self.x.shape[0]\n",
    "\n",
    "         # self.label = np.array(label)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.prev_x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_path, batch_size=72, shuffle=True):\n",
    "    iterator = MidinetDataloader(data_path)\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True}\n",
    "    data_loader = DataLoader(iterator, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "    print('Data loading is completed.')\n",
    "    print(f'{len(data_loader)} batches from {len(iterator)} bars are obtained.')\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading is completed.\n",
      "663 batches from 47723 bars are obtained.\n"
     ]
    }
   ],
   "source": [
    "data_loader = get_dataloader(input_file_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model用共通関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_vector(x, y):\n",
    "    x0, _, x_2, x_3 = x.shape\n",
    "    y2 = y.expand(x_0, y.shape[1], x_2, x_3)\n",
    "    return torch.cat((x, y2),1)\n",
    "    \n",
    "\n",
    "def batch_norm(x, eps=1e-05, momentum=0.9, affine=True):\n",
    "    if x.ndim == 2:\n",
    "        return nn.BatchNorm1d(x.shape[1], eps=eps, momentum=momentum, affine=affine).cuda()(x)\n",
    "    elif x.ndim == 3:\n",
    "        return nn.BatchNorm2d(x.shape[1], eps=eps, momentum=momentum, affine=affine).cuda()(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def lrelu(x, leak=0.2):\n",
    "    z = torch.mul(x,leak)\n",
    "    return torch.max(x, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generator\n",
    "forwardの入力\n",
    "- z (batch, noise_size) = (72, 113): ランダムノイズ\n",
    "- prev_x (batch, ch, steps, pitch) = (72, 1, 16, 128): 前の小節\n",
    "- y (batch, 13): コード，0~11次元はコードの主音，12次元目はmajorかminorかを区別する\n",
    "\n",
    "forwardの出力\n",
    "- g_x (batch, ch, steps, pitch)= (72, 1, 16, 128): 生成された今の小節\n",
    "    \n",
    "オリジナルのmidinetと同じ．詳しい説明はmidinet_understandingを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self,pitch_range=128):\n",
    "        super(generator, self).__init__()\n",
    "        self.gf_dim  = 64\n",
    "        self.y_dim   = 13\n",
    "\n",
    "        self.h1      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h2      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h3      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h4      = nn.ConvTranspose2d(in_channels=157, out_channels=1, kernel_size=(1,pitch_range), stride=(1,2))\n",
    "\n",
    "        self.h0_prev = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(1,pitch_range), stride=(1,2))\n",
    "        self.h1_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h2_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h3_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "\n",
    "        self.linear1 = nn.Linear(113,1024)\n",
    "        self.linear2 = nn.Linear(1037,self.gf_dim*2*2*1)\n",
    "\n",
    "    def forward(self, z, prev_x, y ,batch_size, pitch_range):\n",
    "        \n",
    "        h0_prev = lrelu(batch_norm(self.h0_prev(prev_x)))   # 72, 16, 16, 1\n",
    "        h1_prev = lrelu(batch_norm(self.h1_prev(h0_prev)))  # 72, 16, 8, 1\n",
    "        h2_prev = lrelu(batch_norm(self.h2_prev(h1_prev)))  # 72, 16, 4, 1\n",
    "        h3_prev = lrelu(batch_norm(self.h3_prev(h2_prev)))  # 72, 16, 2, 1\n",
    "\n",
    "        yb = y.view(batch_size,  self.y_dim, 1, 1)          # 72, 13, 1, 1\n",
    "\n",
    "        z = torch.cat((z,y),1)                              # 72, 113\n",
    "\n",
    "        h0 = F.relu(batch_norm(self.linear1(z)))            # 72, 1024\n",
    "        h0 = torch.cat((h0,y),1)   #(72,1037)\n",
    "\n",
    "        h1 = F.relu(batch_norm(self.linear2(h0)))           # 72, 256\n",
    "        h1 = h1.view(batch_size, self.gf_dim * 2, 2, 1)     # 72, 128, 2, 1\n",
    "        h1 = concat_vector(h1, yb)                          # 72, 141, 2, 1\n",
    "        h1 = concat_vector(h1, h3_prev)                     # 72, 157, 2, 1\n",
    "\n",
    "        h2 = F.relu(batch_norm(self.h1(h1)))                # 72, 128, 4, 1\n",
    "        h2 = concat_vector(h2, yb)                          # 72, 141, 4, 1\n",
    "        h2 = concat_vector(h2, h2_prev)                     # 72, 157, 4, 1\n",
    "\n",
    "        h3 = F.relu(batch_norm(self.h2(h2)))                # 72, 128, 8, 1 \n",
    "        h3 = concat_vector(h3, yb)                          # 72, 141, 8, 1\n",
    "        h3 = concat_vector(h3, h1_prev)                     # 72, 157, 8, 1\n",
    "\n",
    "        h4 = F.relu(batch_norm(self.h3(h3)))                # 72, 128, 16, 1\n",
    "        h4 = concat_vector(h4, yb)                          # 72, 141, 16, 1\n",
    "        h4 = concat_vector(h4, h0_prev)                     # 72, 157, 16, 1\n",
    "\n",
    "        g_x = torch.sigmoid(self.h4(h4))                    # 72, 1, 16, 128\n",
    "\n",
    "        return g_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forwardの入力\n",
    "- x (batch, 1, steps, pitch) = (72, 1, 16, 128): real/fake判定を行う小節データ\n",
    "- y (batch, 13) = (72, 13): コード\n",
    "\n",
    "forwardの出力\n",
    "- h3_sigmoid (batch, 1) = (72, 1): 0~1に押し込められたreal/fake判定結果．0はfake, 1はreal\n",
    "- h3 (batch, 1) = (72, 1): 0~1に押し込められていないreal/fake判定結果\n",
    "- fm (batch, 1+13, steps, pitch) = (72, 14, 16, 128): 特徴マップ．\n",
    "\n",
    "オリジナルのmidinetと同じ．詳しい説明はmidinet_understandingを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self,pitch_range=128):\n",
    "        super(discriminator, self).__init__()\n",
    "\n",
    "        self.df_dim = 64\n",
    "        self.dfc_dim = 1024\n",
    "        self.y_dim = 13\n",
    "        \n",
    "        # out channels = y_dim +1 \n",
    "        self.h0_prev = nn.Conv2d(in_channels=14, out_channels=14, kernel_size=(2,pitch_range), stride=(2,2))\n",
    "\n",
    "        # out channels = df_dim + y_dim\n",
    "        self.h1_prev = nn.Conv2d(in_channels=27, out_channels=77, kernel_size=(4,1), stride=(2,2))\n",
    "        self.linear1 = nn.Linear(244, self.dfc_dim)\n",
    "        self.linear2 = nn.Linear(1037, 1)\n",
    "\n",
    "    def forward(self, x, y, batch_size, pitch_range):        \n",
    "\n",
    "        yb = y.view(batch_size,self.y_dim, 1, 1)\n",
    "        x = concat_vector(x, yb)                    #72, 14, 16, 128\n",
    "        \n",
    "        h0 = lrelu(self.h0_prev(x))                 #72, 14, 8, 1\n",
    "        fm = h0\n",
    "        h0 = concat_vector(h0, yb)                  #72, 27, 8, 1\n",
    "\n",
    "        h1 = lrelu(batch_norm(self.h1_prev(h0)))    #72, 77, 3, 1\n",
    "        h1 = h1.view(batch_size, -1)                #72, 231\n",
    "        h1 = torch.cat((h1,y), 1)                   #72, 244\n",
    "\n",
    "        h2 = lrelu(batch_norm(self.linear1(h1)))\n",
    "        h2 = torch.cat((h2,y), 1)                   #72, 1037\n",
    "\n",
    "        h3 = self.linear2(h2)\n",
    "        h3_sigmoid = torch.sigmoid(h3)\n",
    "\n",
    "\n",
    "        return h3_sigmoid, h3, fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コードの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 共通関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_cross_entropy_with_logits(inputs,labels):\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    output = loss(inputs, labels)\n",
    "    return output\n",
    "\n",
    "def reduce_mean(x):\n",
    "    output = torch.mean(x,0, keepdim = False)\n",
    "    output = torch.mean(output,-1, keepdim = False)\n",
    "    return output\n",
    "\n",
    "\n",
    "def reduce_mean_0(x):\n",
    "    output = torch.mean(x,0, keepdim = False)\n",
    "    return output\n",
    "\n",
    "\n",
    "def l2_loss(x,y):\n",
    "    loss_ = nn.MSELoss(reduction='sum')\n",
    "    l2_loss_ = loss_(x, y)/2\n",
    "    return l2_loss_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = 1\n",
    "is_draw = 0\n",
    "is_sample = 0\n",
    "\n",
    "epochs = 20\n",
    "lr = 0.0002\n",
    "\n",
    "check_range_st = 0\n",
    "check_range_ed = 129\n",
    "pitch_range = check_range_ed - check_range_st-1\n",
    "\n",
    "device = torch.device('cuda')\n",
    "train_loader = load_data()\n",
    "\n",
    "# 機能1. 訓練を行う\n",
    "if is_train == 1 :\n",
    "    netG = generator(pitch_range).to(device)\n",
    "    netD = discriminator(pitch_range).to(device)  \n",
    "\n",
    "    netD.train()\n",
    "    netG.train()\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999)) \n",
    "\n",
    "    batch_size = 72\n",
    "    nz = 100\n",
    "    fixed_noise = torch.randn(batch_size, nz, device=device)\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    average_lossD = 0\n",
    "    average_lossG = 0\n",
    "    average_D_x   = 0\n",
    "    average_D_G_z = 0\n",
    "\n",
    "    lossD_list =  []\n",
    "    lossD_list_all = []\n",
    "    lossG_list =  []\n",
    "    lossG_list_all = []\n",
    "    D_x_list = []\n",
    "    D_G_z_list = []\n",
    "    for epoch in range(epochs):\n",
    "        sum_lossD = 0\n",
    "        sum_lossG = 0\n",
    "        sum_D_x   = 0\n",
    "        sum_D_G_z = 0\n",
    "        for i, (data,prev_data,chord) in enumerate(train_loader, 0):\n",
    "\n",
    "            ############################\n",
    "            # (1) Dの学習: log(D(x)) + log(1 - D(G(z))) を最大化\n",
    "            #     realデータを1，fakeデータを0と判断させるよう学習\n",
    "            ###########################\n",
    "\n",
    "            # Dのrealデータに対する訓練\n",
    "\n",
    "            # Dの勾配の初期化\n",
    "            netD.zero_grad()\n",
    "\n",
    "            # バッチ(譜面，前の譜面，コード)をdeviceに渡す  \n",
    "            real_cpu = data.to(device)\n",
    "            prev_data_cpu = prev_data.to(device)\n",
    "            chord_cpu = chord.to(device)\n",
    "\n",
    "            # 全てのデータがrealデータであるというラベルを作成\n",
    "            # このlabel使ってなくない？\n",
    "            batch_size = real_cpu.size(0)\n",
    "            label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "            # Dへ本物データとコードを渡す\n",
    "            D, D_logits, fm = netD(real_cpu,chord_cpu,batch_size,pitch_range)\n",
    "\n",
    "            # realに対して0.9をラベルとしたsigmoid_cross_entropy_with_logits誤差の平均を得る\n",
    "            # なぜ0.9? Dを弱くしたかった？\n",
    "            d_loss_real = reduce_mean(sigmoid_cross_entropy_with_logits(D_logits, 0.9*torch.ones_like(D)))\n",
    "\n",
    "            # 誤差逆伝搬\n",
    "            # retain_graph: 計算グラフの維持．Falseならメモリ節約になるが勾配情報が消えてしまう\n",
    "            d_loss_real.backward(retain_graph=True)\n",
    "\n",
    "            # realデータに対するDの誤差の記録\n",
    "            D_x = D.mean().item()\n",
    "            sum_D_x += D_x \n",
    "\n",
    "\n",
    "\n",
    "            # Dのfakeデータに対する訓練\n",
    "\n",
    "            # ノイズベクトルの作成\n",
    "            noise = torch.randn(batch_size, nz, device=device)\n",
    "\n",
    "            # Gにノイズベクトル，前の譜面，コードを渡し，fakeデータを作成\n",
    "            fake = netG(noise,prev_data_cpu,chord_cpu,batch_size,pitch_range)\n",
    "\n",
    "            # すべてのデータがrealデータであるというラベルを作成\n",
    "            # このlabel使ってなくない？\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # Dへfakeデータとコードを渡す\n",
    "            D_, D_logits_, fm_ = netD(fake.detach(),chord_cpu,batch_size,pitch_range)\n",
    "\n",
    "            # fakeに対して0をラベルとしたsigmoid_cross_entropy_with_logits誤差の平均を得る\n",
    "            d_loss_fake = reduce_mean(sigmoid_cross_entropy_with_logits(D_logits_, torch.zeros_like(D_)))\n",
    "\n",
    "            # 誤差逆伝搬\n",
    "            d_loss_fake.backward(retain_graph=True)\n",
    "            D_G_z1 = D_.mean().item() # fakeへのDのロス．記録しないが表示する\n",
    "\n",
    "            # Dの誤差の記録\n",
    "            errD = d_loss_real + d_loss_fake\n",
    "            errD = errD.item()\n",
    "            lossD_list_all.append(errD)\n",
    "            sum_lossD += errD\n",
    "\n",
    "            # Dの勾配からパラメータを更新\n",
    "            optimizerD.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ############################\n",
    "            # (2) Gの学習(1) : log(D(G(z)))を最大化\n",
    "            #     fakeデータを1と判断させるよう学習\n",
    "            ###########################\n",
    "\n",
    "            # Gの勾配の初期化\n",
    "            netG.zero_grad()\n",
    "\n",
    "            # GはDにfakeデータに対して1を出力してもらいたいのでラベルを逆転\n",
    "            # でもこのlabel使ってなくない？\n",
    "            label.fill_(real_label)\n",
    "\n",
    "            # 先ほど作ったfakeデータ，コードの情報をDへ渡す\n",
    "            # Gはもう一度データを作らなくていいのか？\n",
    "            D_, D_logits_, fm_= netD(fake,chord_cpu,batch_size,pitch_range)\n",
    "\n",
    "            # fakeに対して1をラベルとしたsigmoid_cross_entropy_with_logits誤差の平均を得る\n",
    "            g_loss0 = reduce_mean(sigmoid_cross_entropy_with_logits(D_logits_, torch.ones_like(D_)))\n",
    "\n",
    "            # Dの特徴マッチング：realとfakeでnetDの初段のreluの出力が近くなるようにする\n",
    "            features_from_g = reduce_mean_0(fm_) # fakeデータに対するDのfeatureの平均値\n",
    "            features_from_i = reduce_mean_0(fm)  # realデータに対するDのfeatureの平均値\n",
    "            # fakeとrealの出すfeatureの違いが大きいほどペナルティを与える\n",
    "            fm_g_loss1 =torch.mul(l2_loss(features_from_g, features_from_i), 0.1)\n",
    "\n",
    "            # Gの特徴マッチング：Gがrealに近いデータを生成できるようにする\n",
    "            mean_image_from_g = reduce_mean_0(fake)      # fakeデータの平均値\n",
    "            smean_image_from_i = reduce_mean_0(real_cpu) # realデータの平均値\n",
    "            # fakeデータとrealデータの違いが大きいほどペナルティを与える\n",
    "            fm_g_loss2 = torch.mul(l2_loss(mean_image_from_g, smean_image_from_i), 0.01)\n",
    "\n",
    "            # Gの誤差の記録(listへは追加しない)\n",
    "            errG = g_loss0 + fm_g_loss1 + fm_g_loss2\n",
    "\n",
    "            # 誤差逆伝搬\n",
    "            errG.backward(retain_graph=True)\n",
    "            D_G_z2 = D_.mean().item() # fakeへのDのロス．記録しないが表示する\n",
    "\n",
    "            # Gの勾配からパラメータを更新\n",
    "            optimizerG.step()\n",
    "\n",
    "\n",
    "\n",
    "            ############################\n",
    "            # (3) Gの学習(2) : log(D(G(z)))を再び最大化\n",
    "            #     Gの学習(1)と同じ\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for generator cost\n",
    "            D_, D_logits_, fm_ = netD(fake,chord_cpu,batch_size,pitch_range)\n",
    "\n",
    "            ###loss\n",
    "            g_loss0 = reduce_mean(sigmoid_cross_entropy_with_logits(D_logits_, torch.ones_like(D_)))\n",
    "            #Feature Matching\n",
    "            features_from_g = reduce_mean_0(fm_)\n",
    "            features_from_i = reduce_mean_0(fm)\n",
    "            loss_ = nn.MSELoss(reduction='sum') # 書き方は変わっているが，opts化したのを忘れている模様\n",
    "            feature_l2_loss = loss_(features_from_g, features_from_i)/2\n",
    "            fm_g_loss1 =torch.mul(feature_l2_loss, 0.1)\n",
    "\n",
    "            mean_image_from_g = reduce_mean_0(fake)\n",
    "            smean_image_from_i = reduce_mean_0(real_cpu)\n",
    "            mean_l2_loss = loss_(mean_image_from_g, smean_image_from_i)/2\n",
    "            fm_g_loss2 = torch.mul(mean_l2_loss, 0.01)\n",
    "            errG = g_loss0 + fm_g_loss1 + fm_g_loss2\n",
    "            sum_lossG +=errG\n",
    "            errG.backward()\n",
    "            lossG_list_all.append(errG.item()) # 2回目のGの学習ではロスの記録を行う\n",
    "\n",
    "            D_G_z2 = D_.mean().item()\n",
    "            sum_D_G_z += D_G_z2\n",
    "            optimizerG.step()\n",
    "\n",
    "\n",
    "            # 5エポックごとにロスの状況を表示\n",
    "            # epochではなくiでは？バッチごとに出力されてしまわないか？\n",
    "            if epoch % 5 == 0:\n",
    "                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                      % (epoch, epochs, i, len(train_loader),\n",
    "                         errD, errG, D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "            # realデータとfakeデータを比較できるよう画像で保存\n",
    "            if i % 100 == 0:\n",
    "                vutils.save_image(real_cpu,\n",
    "                        '%s/real_samples.png' % 'file',\n",
    "                        normalize=True)\n",
    "                fake = netG(fixed_noise,prev_data_cpu,chord_cpu,batch_size,pitch_range)\n",
    "                vutils.save_image(fake.detach(),\n",
    "                        '%s/fake_samples_epoch_%03d.png' % ('file', epoch),\n",
    "                        normalize=True)\n",
    "\n",
    "        # エポックごとの誤差の記録\n",
    "        average_lossD = (sum_lossD / len(train_loader.dataset))\n",
    "        average_lossG = (sum_lossG / len(train_loader.dataset))\n",
    "        average_D_x = (sum_D_x / len(train_loader.dataset))\n",
    "        average_D_G_z = (sum_D_G_z / len(train_loader.dataset))\n",
    "\n",
    "        lossD_list.append(average_lossD)\n",
    "        lossG_list.append(average_lossG)            \n",
    "        D_x_list.append(average_D_x)\n",
    "        D_G_z_list.append(average_D_G_z)\n",
    "\n",
    "        print('==> Epoch: {} Average lossD: {:.10f} average_lossG: {:.10f},average D(x): {:.10f},average D(G(z)): {:.10f} '.format(\n",
    "          epoch, average_lossD,average_lossG,average_D_x, average_D_G_z)) \n",
    "\n",
    "    # 記録の保存\n",
    "    np.save('lossD_list.npy',lossD_list)\n",
    "    np.save('lossG_list.npy',lossG_list)\n",
    "    np.save('lossD_list_all.npy',lossD_list_all)\n",
    "    np.save('lossG_list_all.npy',lossG_list_all)\n",
    "    np.save('D_x_list.npy',D_x_list)\n",
    "    np.save('D_G_z_list.npy',D_G_z_list)\n",
    "\n",
    "    # モデルの保存\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % ('../models', epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % ('../models', epoch))\n",
    "\n",
    "\n",
    "\n",
    "# 機能2. 誤差のグラフを作成する\n",
    "if is_draw == 1:\n",
    "    lossD_print = np.load('lossD_list.npy')\n",
    "    lossG_print = np.load('lossG_list.npy')\n",
    "    length = lossG_print.shape[0]\n",
    "\n",
    "    x = np.linspace(0, length-1, length)\n",
    "    x = np.asarray(x)\n",
    "    plt.figure()\n",
    "    plt.plot(x, lossD_print,label=' lossD',linewidth=1.5)\n",
    "    plt.plot(x, lossG_print,label=' lossG',linewidth=1.5)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('data')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig('where you want to save/lr='+ str(lr) +'_epoch='+str(epochs)+'.png')\n",
    "\n",
    "\n",
    "\n",
    "# 機能3. サンプルを作成する\n",
    "if is_sample == 1:\n",
    "    batch_size = 8\n",
    "    nz = 100\n",
    "    n_bars = 7\n",
    "\n",
    "    # データの取得\n",
    "    X_te = np.load('your testing x') # 最初の小節\n",
    "    prev_X_te = np.load('your testing prev x') # 前の小節\n",
    "    prev_X_te = prev_X_te[:,:,check_range_st:check_range_ed,:]\n",
    "    y_te    = np.load('yourd chord') # コード\n",
    "\n",
    "    # DataLoaderの準備\n",
    "    test_iter = get_dataloader(X_te,prev_X_te,y_te)\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True}# if args.cuda else {}\n",
    "    test_loader = DataLoader(test_iter, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    # サンプル生成用のGを用意し，訓練済みパラメータを読み込ませる\n",
    "    netG = sample_generator()\n",
    "    netG.load_state_dict(torch.load('your model'))\n",
    "\n",
    "    # サンプルの生成ループ\n",
    "    output_songs = []\n",
    "    output_chords = []\n",
    "    for i, (data,prev_data,chord) in enumerate(test_loader, 0):\n",
    "        list_song = []\n",
    "        first_bar = data[0].view(1,1,16,128)\n",
    "        list_song.append(first_bar)\n",
    "\n",
    "        list_chord = []\n",
    "        first_chord = chord[0].view(1,13).numpy()\n",
    "        list_chord.append(first_chord)\n",
    "        noise = torch.randn(batch_size, nz)\n",
    "\n",
    "        # 小節生成ループ\n",
    "        for bar in range(n_bars):\n",
    "            z = noise[bar].view(1,nz)\n",
    "            y = chord[bar].view(1,13)\n",
    "\n",
    "            if bar == 0:\n",
    "                # 最初の小節はrealデータを使う\n",
    "                prev = data[0].view(1,1,16,128)\n",
    "            else:\n",
    "                # 2小節目からは前の小節を条件にする\n",
    "                prev = list_song[bar-1].view(1,1,16,128)\n",
    "\n",
    "            # ランダムノイズを基に，前の小節と今のコードを条件として渡して，今の小節を生成\n",
    "            sample = netG(z, prev, y, 1,pitch_range)\n",
    "\n",
    "            # 小節を記録\n",
    "            list_song.append(sample)\n",
    "            list_chord.append(y.numpy())\n",
    "\n",
    "        # 生成された曲を記録\n",
    "        print('num of output_songs: {}'.format(len(output_songs)))\n",
    "        output_songs.append(list_song)\n",
    "        output_chords.append(list_chord)\n",
    "\n",
    "    # 生成された曲の保存\n",
    "    np.save('output_songs.npy',np.asarray(output_songs))\n",
    "    np.save('output_chords.npy',np.asarray(output_chords))\n",
    "\n",
    "    print('creation completed, check out what I make!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
