{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MidiNetモデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataLoaderの作成\n",
    "- Modelの作成\n",
    "- 学習コードの作成\n",
    "- 学習経過の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, ipdb, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from pypianoroll import Multitrack, Track\n",
    "from utils import grid_plot, Timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../datasets/theorytab/midinet\"\n",
    "output_dir = f\"{base_dir}/learning\"\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidinetDataloader():\n",
    "    def __init__(self, data_path, pitch_range=[0,128], show_shape=False):\n",
    "        data = pickle.load(open(data_path,'rb'))\n",
    "        \n",
    "        melody, prev, chord = [], [], []\n",
    "        for m, p, c in data:\n",
    "            melody.append(m)\n",
    "            prev.append(p)\n",
    "            chord.append(c)\n",
    "        \n",
    "        self.size = len(melody)\n",
    "        steps = len(melody[0])\n",
    "        bottom, top = pitch_range\n",
    "        \n",
    "        melody = np.array(melody)[:,:,bottom:top].reshape(self.size, 1, steps, top-bottom)\n",
    "        prev = np.array(prev)[:,:,bottom:top].reshape(self.size, 1, steps, top-bottom)\n",
    "        chord = np.array(chord)\n",
    "        \n",
    "        if show_shape:\n",
    "            print(\"melody shape\", melody.shape)\n",
    "            print(\"prev shape\", prev.shape)\n",
    "            print(\"chord shape\", chord.shape)\n",
    "        \n",
    "        self.x = torch.from_numpy(melody).float()\n",
    "        self.prev_x   = torch.from_numpy(prev).float()\n",
    "        self.y  = torch.from_numpy(chord).float()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.prev_x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_path, batch_size=72, shuffle=True):\n",
    "    iterator = MidinetDataloader(data_path)\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True}\n",
    "    data_loader = DataLoader(iterator, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "    print('Data loading is completed.')\n",
    "    print(f'{len(data_loader)} batches from {len(iterator)} bars are obtained.')\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data):\n",
    "    if not isinstance(data, torch.Tensor):\n",
    "        data = torch.from_numpy(data)\n",
    "    if torch.cuda.is_available():\n",
    "        return data.cuda()\n",
    "    return data.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model用共通関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_vector(x, y):\n",
    "    x_0, _, x_2, x_3 = x.shape\n",
    "    y2 = y.expand(x_0, y.shape[1], x_2, x_3)\n",
    "    return torch.cat((x, y2),1)\n",
    "    \n",
    "\n",
    "def batch_norm(x, eps=1e-05, momentum=0.9, affine=True):\n",
    "    if x.ndim == 2:\n",
    "        return nn.BatchNorm1d(x.shape[1], eps=eps, momentum=momentum, affine=affine).cuda()(x)\n",
    "    elif x.ndim == 3:\n",
    "        return nn.BatchNorm2d(x.shape[1], eps=eps, momentum=momentum, affine=affine).cuda()(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def lrelu(x, leak=0.2):\n",
    "    z = torch.mul(x,leak)\n",
    "    return torch.max(x, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "forwardの入力\n",
    "- z (batch, noise_size) = (72, 113): ランダムノイズ\n",
    "- prev_x (batch, ch, steps, pitch) = (72, 1, 16, 128): 前の小節\n",
    "- y (batch, 13): コード，0~11次元はコードの主音，12次元目はmajorかminorかを区別する\n",
    "\n",
    "forwardの出力\n",
    "- g_x (batch, ch, steps, pitch)= (72, 1, 16, 128): 生成された今の小節\n",
    "    \n",
    "オリジナルのmidinetと同じ．詳しい説明はmidinet_understandingを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,pitch_range=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gf_dim  = 64\n",
    "        self.y_dim   = 13\n",
    "\n",
    "        self.h1      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h2      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h3      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h4      = nn.ConvTranspose2d(in_channels=157, out_channels=1, kernel_size=(1,pitch_range), stride=(1,2))\n",
    "\n",
    "        self.h0_prev = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(1,pitch_range), stride=(1,2))\n",
    "        self.h1_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h2_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h3_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "\n",
    "        self.linear1 = nn.Linear(113,1024)\n",
    "        self.linear2 = nn.Linear(1037,self.gf_dim*2*2*1)\n",
    "\n",
    "    def forward(self, z, prev_x, y, batch_size):\n",
    "        \n",
    "        h0_prev = lrelu(batch_norm(self.h0_prev(prev_x)))   # 72, 16, 16, 1\n",
    "        h1_prev = lrelu(batch_norm(self.h1_prev(h0_prev)))  # 72, 16, 8, 1\n",
    "        h2_prev = lrelu(batch_norm(self.h2_prev(h1_prev)))  # 72, 16, 4, 1\n",
    "        h3_prev = lrelu(batch_norm(self.h3_prev(h2_prev)))  # 72, 16, 2, 1\n",
    "\n",
    "        yb = y.view(batch_size, self.y_dim, 1, 1)           # 72, 13, 1, 1\n",
    "\n",
    "        z = torch.cat((z,y),1)                              # 72, 113\n",
    "\n",
    "        h0 = F.relu(batch_norm(self.linear1(z)))            # 72, 1024\n",
    "        h0 = torch.cat((h0,y),1)                            # 72, 1037\n",
    "\n",
    "        h1 = F.relu(batch_norm(self.linear2(h0)))           # 72, 256\n",
    "        h1 = h1.view(batch_size, self.gf_dim * 2, 2, 1)     # 72, 128, 2, 1\n",
    "        h1 = concat_vector(h1, yb)                          # 72, 141, 2, 1\n",
    "        h1 = concat_vector(h1, h3_prev)                     # 72, 157, 2, 1\n",
    "\n",
    "        h2 = F.relu(batch_norm(self.h1(h1)))                # 72, 128, 4, 1\n",
    "        h2 = concat_vector(h2, yb)                          # 72, 141, 4, 1\n",
    "        h2 = concat_vector(h2, h2_prev)                     # 72, 157, 4, 1\n",
    "\n",
    "        h3 = F.relu(batch_norm(self.h2(h2)))                # 72, 128, 8, 1 \n",
    "        h3 = concat_vector(h3, yb)                          # 72, 141, 8, 1\n",
    "        h3 = concat_vector(h3, h1_prev)                     # 72, 157, 8, 1\n",
    "\n",
    "        h4 = F.relu(batch_norm(self.h3(h3)))                # 72, 128, 16, 1\n",
    "        h4 = concat_vector(h4, yb)                          # 72, 141, 16, 1\n",
    "        h4 = concat_vector(h4, h0_prev)                     # 72, 157, 16, 1\n",
    "\n",
    "        g_x = torch.sigmoid(self.h4(h4))                    # 72, 1, 16, 128\n",
    "\n",
    "        return g_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator\n",
    "forwardの入力\n",
    "- x (batch, 1, steps, pitch) = (72, 1, 16, 128): real/fake判定を行う小節データ\n",
    "- y (batch, 13) = (72, 13): コード\n",
    "\n",
    "forwardの出力\n",
    "- h3_sigmoid (batch, 1) = (72, 1): 0~1に押し込められたreal/fake判定結果．0はfake, 1はreal\n",
    "- h3 (batch, 1) = (72, 1): 0~1に押し込められていないreal/fake判定結果\n",
    "- fm (batch, 1+13, steps, pitch) = (72, 14, 16, 128): 特徴マップ．\n",
    "\n",
    "オリジナルのmidinetと同じ．詳しい説明はmidinet_understandingを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,pitch_range=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.df_dim = 64\n",
    "        self.dfc_dim = 1024\n",
    "        self.y_dim = 13\n",
    "        \n",
    "        # out channels = y_dim +1 \n",
    "        self.h0_prev = nn.Conv2d(in_channels=14, out_channels=14, kernel_size=(2,pitch_range), stride=(2,2))\n",
    "\n",
    "        # out channels = df_dim + y_dim\n",
    "        self.h1_prev = nn.Conv2d(in_channels=27, out_channels=77, kernel_size=(4,1), stride=(2,2))\n",
    "        self.linear1 = nn.Linear(244, self.dfc_dim)\n",
    "        self.linear2 = nn.Linear(1037, 1)\n",
    "\n",
    "    def forward(self, x, y, batch_size):        \n",
    "\n",
    "        yb = y.view(batch_size,self.y_dim, 1, 1)\n",
    "        x = concat_vector(x, yb)                    #72, 14, 16, 128\n",
    "        \n",
    "        h0 = lrelu(self.h0_prev(x))                 #72, 14, 8, 1\n",
    "        fm = h0\n",
    "        h0 = concat_vector(h0, yb)                  #72, 27, 8, 1\n",
    "\n",
    "        h1 = lrelu(batch_norm(self.h1_prev(h0)))    #72, 77, 3, 1\n",
    "        h1 = h1.view(batch_size, -1)                #72, 231\n",
    "        h1 = torch.cat((h1,y), 1)                   #72, 244\n",
    "\n",
    "        h2 = lrelu(batch_norm(self.linear1(h1)))\n",
    "        h2 = torch.cat((h2,y), 1)                   #72, 1037\n",
    "\n",
    "        h3 = self.linear2(h2)\n",
    "        h3_sigmoid = torch.sigmoid(h3)\n",
    "\n",
    "\n",
    "        return h3_sigmoid, h3, fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コードの作成: original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = os.path.join(base_dir, \"midinet_original.pkl\")\n",
    "save_dir = os.path.join(output_dir, \"original\")\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "save_npa = lambda file_name, npa: np.save(os.path.join(save_dir, file_name), npa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 512\n",
    "generator_train_times = 2\n",
    "sample_bar_num = 16 # あとで実装\n",
    "\n",
    "# for Adam\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "\n",
    "# noise vector size\n",
    "nz = 100\n",
    "\n",
    "# a coefficient to real label for discriminator. 0 ~ 1\n",
    "real_data_worthiness = 0.9\n",
    "\n",
    "# feature matching coefficients\n",
    "lambda_1, lambda_2 = 0.1, 0.01 # D, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習初期化処理  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading is completed.\n",
      "279 batches from 142740 bars are obtained.\n"
     ]
    }
   ],
   "source": [
    "data_loader = get_dataloader(input_file_path, batch_size=batch_size)\n",
    "data_size = len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator()\n",
    "netG = Generator()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    netD = netD.cuda()\n",
    "    netG = netG.cuda()\n",
    "\n",
    "netD.train()\n",
    "netG.train()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=betas)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "noise_for_sample = to_device(torch.randn(sample_bar_num, nz))\n",
    "\n",
    "realD_list, fakeD_list = [], [] # Dのrealデータとfakeデータに対するエポックごとの識別結果平均(realに対しては1に近く，fakeに対しては0に近い方がDが強い)\n",
    "lossD_list, lossG_list = [], [] # D, Gのロスのエポックごとの誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習ループ\n",
    "オリジナルのコードを若干書き換え  \n",
    "ノイズベクトルは毎回作り直すことにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0 / 20\n",
      "==> avg lossD: 0.0025 avg lossG: 0.0020, avg realD: 0.0009, avg fakeD: 0.0008 \n",
      "13.466941\n",
      "[epoch 0] loss D: 1.0889 loss G: 1.2906 real D: 0.6297 fake D: 0.4298\n",
      "start epoch 1 / 20\n",
      "==> avg lossD: 0.0020 avg lossG: 0.0024, avg realD: 0.0011, avg fakeD: 0.0006 \n",
      "13.381445\n",
      "start epoch 2 / 20\n",
      "==> avg lossD: 0.0019 avg lossG: 0.0026, avg realD: 0.0012, avg fakeD: 0.0006 \n",
      "13.457835\n",
      "start epoch 3 / 20\n",
      "==> avg lossD: 0.0021 avg lossG: 0.0023, avg realD: 0.0011, avg fakeD: 0.0007 \n",
      "13.556808\n",
      "start epoch 4 / 20\n",
      "==> avg lossD: 0.0022 avg lossG: 0.0022, avg realD: 0.0011, avg fakeD: 0.0007 \n",
      "13.210067\n",
      "start epoch 5 / 20\n",
      "==> avg lossD: 0.0017 avg lossG: 0.0029, avg realD: 0.0012, avg fakeD: 0.0005 \n",
      "13.417396\n",
      "[epoch 5] loss D: 0.6689 loss G: 1.7631 real D: 0.7298 fake D: 0.2131\n",
      "start epoch 6 / 20\n",
      "==> avg lossD: 0.0017 avg lossG: 0.0031, avg realD: 0.0013, avg fakeD: 0.0005 \n",
      "11.883087\n",
      "start epoch 7 / 20\n",
      "==> avg lossD: 0.0021 avg lossG: 0.0023, avg realD: 0.0011, avg fakeD: 0.0007 \n",
      "13.566569\n",
      "start epoch 8 / 20\n",
      "==> avg lossD: 0.0021 avg lossG: 0.0023, avg realD: 0.0011, avg fakeD: 0.0007 \n",
      "13.433684\n",
      "start epoch 9 / 20\n",
      "==> avg lossD: 0.0019 avg lossG: 0.0027, avg realD: 0.0012, avg fakeD: 0.0006 \n",
      "13.407630\n",
      "start epoch 10 / 20\n",
      "==> avg lossD: 0.0024 avg lossG: 0.0019, avg realD: 0.0010, avg fakeD: 0.0008 \n",
      "13.370852\n",
      "[epoch 10] loss D: 1.2835 loss G: 0.9971 real D: 0.5243 fake D: 0.4418\n",
      "start epoch 11 / 20\n",
      "0.452404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/midinet-followup/.venv/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 21, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/root/midinet-followup/.venv/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 284, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/connection.py\", line 498, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/connection.py\", line 741, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/root/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 3543) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/midinet-followup/.venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/midinet-followup/.venv/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 3543) is killed by signal: Bus error. ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1439b253727b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"start epoch {epoch} / {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# バッチ(譜面，前の譜面，コード)をdeviceに渡す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/midinet-followup/.venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/midinet-followup/.venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/midinet-followup/.venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 3543) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    sum_lossD, sum_lossG = 0, 0\n",
    "    sum_realD, sum_fakeD = 0, 0\n",
    "    \n",
    "    print(f\"start epoch {epoch} / {epochs}\")\n",
    "    with Timer():\n",
    "        for i, (real, prev, chord) in enumerate(data_loader):\n",
    "\n",
    "            # バッチ(譜面，前の譜面，コード)をdeviceに渡す  \n",
    "            real, prev, chord = [to_device(item) for item in [real, prev, chord]]\n",
    "\n",
    "            # batchの切れ端はサイズが異なる場合があるので注意\n",
    "            batch_size = real.size(0)\n",
    "\n",
    "            ############################\n",
    "            # Dの学習: log(D(x)) + log(1 - D(G(z))) を最大化\n",
    "            # realデータを1，fakeデータを0と判断させるよう学習\n",
    "            ###########################\n",
    "\n",
    "            # Dの勾配の初期化\n",
    "            netD.zero_grad()\n",
    "\n",
    "            # realに対する識別結果からクロスエントロピー誤差(目的関数)の値を得る\n",
    "            d_real, d_logits_real, fm_real = netD(real, chord, batch_size)\n",
    "            d_real_label = real_data_worthiness * torch.ones_like(d_real)\n",
    "            d_loss_real = nn.BCEWithLogitsLoss()(d_logits_real, d_real_label) # (72, 1), (72, 1) => scalar tensor\n",
    "\n",
    "            # Gにノイズベクトル，前の譜面，コードを渡し，fakeデータを作成\n",
    "            noise = to_device(torch.randn(batch_size, nz))\n",
    "            fake = netG(noise, prev, chord, batch_size)\n",
    "\n",
    "            # fakeに対する識別結果からクロスエントロピー誤差(目的関数)の値を得る\n",
    "            d_fake, d_logits_fake, fm_fake = netD(fake.detach(), chord, batch_size)\n",
    "            d_fake_label = torch.zeros_like(d_fake)\n",
    "            d_loss_fake = nn.BCEWithLogitsLoss()(d_logits_fake, d_fake_label) # (72, 1), (72, 1) => scalar tensor\n",
    "\n",
    "            # 誤差逆伝搬により勾配を更新し，それに基づきDのパラメータを更新する\n",
    "            lossD = d_loss_real + d_loss_fake\n",
    "            lossD.backward(retain_graph=True)\n",
    "            optimizerD.step()\n",
    "\n",
    "            # 学習記録\n",
    "            # real, fakeデータに対してそれぞれrealだと識別した割合\n",
    "            realD, fakeD = d_real.mean().item(), d_fake.mean().item()\n",
    "            sum_realD += realD\n",
    "            sum_fakeD += fakeD\n",
    "            sum_lossD += lossD.item() # Dの学習におけるLoss\n",
    "\n",
    "\n",
    "            ############################\n",
    "            # Gの学習 : log(D(G(z)))を最大化\n",
    "            # fakeデータを1と判断させるよう学習\n",
    "            ###########################\n",
    "\n",
    "            for t in range(generator_train_times):\n",
    "\n",
    "                # Gの勾配の初期化\n",
    "                netG.zero_grad()\n",
    "\n",
    "                # Gにノイズベクトル，前の譜面，コードを渡し，fakeデータを作成\n",
    "                noise = to_device(torch.randn(batch_size, nz))\n",
    "                fake = netG(noise, prev, chord, batch_size)\n",
    "                \n",
    "                # fakeに対して1をラベルとした識別結果からクロスエントロピー誤差(目的関数)の値を得てGの誤差とする\n",
    "                d_fake, d_logits_fake, fm_fake = netD(fake, chord, batch_size)\n",
    "                deceive_label = torch.ones_like(d_fake)\n",
    "                g_loss = nn.BCEWithLogitsLoss()(d_logits_fake, deceive_label) # (72, 1), (72, 1) => scalar tensor\n",
    "\n",
    "                # Dの特徴マッチング：realとfakeでnetDの初段のreluの出力が近くなるようにする\n",
    "                features_from_g = torch.mean(fm_fake, 0) # fakeデータに対するDのfeatureの平均値\n",
    "                features_from_i = torch.mean(fm_real, 0) # realデータに対するDのfeatureの平均値\n",
    "                # fakeとrealの出すfeatureの違いが大きいほどペナルティを与える\n",
    "                fm_g_loss1 = nn.MSELoss(reduction='sum')(features_from_g, features_from_i) / 2\n",
    "                fm_g_loss1 = torch.mul(fm_g_loss1, lambda_1)\n",
    "\n",
    "                # Gの特徴マッチング：Gがrealに近いデータを生成できるようにする\n",
    "                mean_image_from_g = torch.mean(fake, 0) # fakeデータの平均値\n",
    "                mean_image_from_i = torch.mean(real, 0) # realデータの平均値\n",
    "                # fakeデータとrealデータの違いが大きいほどペナルティを与える\n",
    "                fm_g_loss2 = nn.MSELoss(reduction='sum')(mean_image_from_g, mean_image_from_i) / 2\n",
    "                fm_g_loss2 = torch.mul(fm_g_loss2, lambda_2)\n",
    "\n",
    "                # 誤差逆伝搬により勾配を更新し，それに基づきGのパラメータを更新する\n",
    "                lossG = g_loss + fm_g_loss1 + fm_g_loss2\n",
    "                lossG.backward(retain_graph=(t < generator_train_times - 1)) # 最後は計算グラフを放棄\n",
    "                optimizerG.step()\n",
    "\n",
    "            # 学習記録\n",
    "            sum_lossG += lossG.item() # Gの学習におけるLoss\n",
    "    \n",
    "\n",
    "        # エポックごとの識別と誤差の記録\n",
    "        realD_list.append(sum_realD / data_size)\n",
    "        fakeD_list.append(sum_fakeD / data_size)\n",
    "        lossD_list.append(sum_lossD / data_size)\n",
    "        lossG_list.append(sum_lossG / data_size)\n",
    "        print(f'==> avg lossD: {lossD_list[-1]:.4f} avg lossG: {lossG_list[-1]:.4f}, avg realD: {realD_list[-1]:.4f}, avg fakeD: {fakeD_list[-1]:.4f} ')\n",
    "    \n",
    "    # 5エポックごとに具体的なロスと識別の状況を報告し，生成データを画像で記録\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'[epoch {epoch}] loss D: {lossD:.4f} loss G: {lossG:.4f} real D: {realD:.4f} fake D: {fakeD:.4f}')\n",
    "        sample_fake = netG(noise_for_sample, prev[:sample_bar_num], chord[:sample_bar_num], sample_bar_num).detach()\n",
    "        fake_file_name = f'fake_samples_epoch{epoch:03}.png'\n",
    "        vutils.save_image(sample_fake, os.path.join(save_dir, fake_file_name), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルと記録の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npa('realD_list.npy', realD_list)\n",
    "save_npa('fakeD_list.npy', fakeD_list)\n",
    "save_npa('lossD_list.npy', lossD_list)\n",
    "save_npa('lossG_list.npy', lossG_list)\n",
    "torch.save(netG.state_dict(), os.path.join(save_dir, f'netG_epoch_{epoch}.pth'))\n",
    "torch.save(netD.state_dict(), os.path.join(save_dir, f'netD_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差グラフの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossD_print = np.load(os.path.join(save_dir, 'lossD_list.npy'))\n",
    "lossG_print = np.load(os.path.join(save_dir, 'lossG_list.npy'))\n",
    "\n",
    "length = lossG_print.shape[0]\n",
    "x = np.asarray(np.linspace(0, length-1, length))\n",
    "plt.figure()\n",
    "plt.plot(x, lossD_print,label=' lossD',linewidth=1.5)\n",
    "plt.plot(x, lossG_print,label=' lossG',linewidth=1.5)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(os.path.join(save_dir, f'loss_graph_lr={lr}_epoch={epochs}.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "nz = 100\n",
    "n_bars = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの取得\n",
    "X_te = np.load('your testing x') # 最初の小節\n",
    "prev_X_te = np.load('your testing prev x') # 前の小節\n",
    "prev_X_te = prev_X_te[:,:,check_range_st:check_range_ed,:]\n",
    "y_te    = np.load('yourd chord') # コード\n",
    "\n",
    "# DataLoaderの準備\n",
    "test_iter = get_dataloader(X_te,prev_X_te,y_te)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True}# if args.cuda else {}\n",
    "test_loader = DataLoader(test_iter, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# サンプル生成用のGを用意し，訓練済みパラメータを読み込ませる\n",
    "netG = sample_generator()\n",
    "netG.load_state_dict(torch.load('your model'))\n",
    "\n",
    "# サンプルの生成ループ\n",
    "output_songs = []\n",
    "output_chords = []\n",
    "for i, (data,prev_data,chord) in enumerate(test_loader, 0):\n",
    "    list_song = []\n",
    "    first_bar = data[0].view(1,1,16,128)\n",
    "    list_song.append(first_bar)\n",
    "\n",
    "    list_chord = []\n",
    "    first_chord = chord[0].view(1,13).numpy()\n",
    "    list_chord.append(first_chord)\n",
    "    noise = torch.randn(batch_size, nz)\n",
    "\n",
    "    # 小節生成ループ\n",
    "    for bar in range(n_bars):\n",
    "        z = noise[bar].view(1,nz)\n",
    "        y = chord[bar].view(1,13)\n",
    "\n",
    "        if bar == 0:\n",
    "            # 最初の小節はrealデータを使う\n",
    "            prev = data[0].view(1,1,16,128)\n",
    "        else:\n",
    "            # 2小節目からは前の小節を条件にする\n",
    "            prev = list_song[bar-1].view(1,1,16,128)\n",
    "\n",
    "        # ランダムノイズを基に，前の小節と今のコードを条件として渡して，今の小節を生成\n",
    "        sample = netG(z, prev, y, 1, pitch_range)\n",
    "\n",
    "        # 小節を記録\n",
    "        list_song.append(sample)\n",
    "        list_chord.append(y.numpy())\n",
    "\n",
    "    # 生成された曲を記録\n",
    "    print('num of output_songs: {}'.format(len(output_songs)))\n",
    "    output_songs.append(list_song)\n",
    "    output_chords.append(list_chord)\n",
    "\n",
    "# 生成された曲の保存\n",
    "np.save('output_songs.npy',np.asarray(output_songs))\n",
    "np.save('output_chords.npy',np.asarray(output_chords))\n",
    "\n",
    "print('creation completed, check out what I make!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
