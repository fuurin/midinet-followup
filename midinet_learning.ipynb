{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MidiNetモデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataLoaderの作成\n",
    "- Modelの作成\n",
    "- 学習コードの作成\n",
    "- 学習経過の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, ipdb, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from pypianoroll import Multitrack, Track\n",
    "from utils import grid_plot, Timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../datasets/theorytab/midinet\"\n",
    "output_dir = f\"{base_dir}/learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidinetDataloader():\n",
    "    def __init__(self, data_path):\n",
    "        data = pickle.load(open(data_path,'rb'))\n",
    "        \n",
    "        melody, prev, chord = [], [], []\n",
    "        for m, p, c in data:\n",
    "            melody.append(m)\n",
    "            prev.append(p)\n",
    "            chord.append(c)\n",
    "        \n",
    "        self.x = torch.from_numpy(np.array(melody)).float()\n",
    "        self.prev_x   = torch.from_numpy(np.array(prev)).float()\n",
    "        self.y  = torch.from_numpy(np.array(chord)).float()\n",
    "        self.size = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.prev_x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_path, batch_size=72, shuffle=True):\n",
    "    iterator = MidinetDataloader(data_path)\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True}\n",
    "    data_loader = DataLoader(iterator, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "    print('Data loading is completed.')\n",
    "    print(f'{len(data_loader)} batches from {len(iterator)} bars are obtained.')\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model用共通関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_vector(x, y):\n",
    "    x0, _, x_2, x_3 = x.shape\n",
    "    y2 = y.expand(x_0, y.shape[1], x_2, x_3)\n",
    "    return torch.cat((x, y2),1)\n",
    "    \n",
    "\n",
    "def batch_norm(x, eps=1e-05, momentum=0.9, affine=True):\n",
    "    if x.ndim == 2:\n",
    "        return nn.BatchNorm1d(x.shape[1], eps=eps, momentum=momentum, affine=affine).cuda()(x)\n",
    "    elif x.ndim == 3:\n",
    "        return nn.BatchNorm2d(x.shape[1], eps=eps, momentum=momentum, affine=affine).cuda()(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def lrelu(x, leak=0.2):\n",
    "    z = torch.mul(x,leak)\n",
    "    return torch.max(x, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "forwardの入力\n",
    "- z (batch, noise_size) = (72, 113): ランダムノイズ\n",
    "- prev_x (batch, ch, steps, pitch) = (72, 1, 16, 128): 前の小節\n",
    "- y (batch, 13): コード，0~11次元はコードの主音，12次元目はmajorかminorかを区別する\n",
    "\n",
    "forwardの出力\n",
    "- g_x (batch, ch, steps, pitch)= (72, 1, 16, 128): 生成された今の小節\n",
    "    \n",
    "オリジナルのmidinetと同じ．詳しい説明はmidinet_understandingを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,pitch_range=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gf_dim  = 64\n",
    "        self.y_dim   = 13\n",
    "\n",
    "        self.h1      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h2      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h3      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h4      = nn.ConvTranspose2d(in_channels=157, out_channels=1, kernel_size=(1,pitch_range), stride=(1,2))\n",
    "\n",
    "        self.h0_prev = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(1,pitch_range), stride=(1,2))\n",
    "        self.h1_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h2_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "        self.h3_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
    "\n",
    "        self.linear1 = nn.Linear(113,1024)\n",
    "        self.linear2 = nn.Linear(1037,self.gf_dim*2*2*1)\n",
    "\n",
    "    def forward(self, z, prev_x, y ,batch_size, pitch_range):\n",
    "        \n",
    "        h0_prev = lrelu(batch_norm(self.h0_prev(prev_x)))   # 72, 16, 16, 1\n",
    "        h1_prev = lrelu(batch_norm(self.h1_prev(h0_prev)))  # 72, 16, 8, 1\n",
    "        h2_prev = lrelu(batch_norm(self.h2_prev(h1_prev)))  # 72, 16, 4, 1\n",
    "        h3_prev = lrelu(batch_norm(self.h3_prev(h2_prev)))  # 72, 16, 2, 1\n",
    "\n",
    "        yb = y.view(batch_size,  self.y_dim, 1, 1)          # 72, 13, 1, 1\n",
    "\n",
    "        z = torch.cat((z,y),1)                              # 72, 113\n",
    "\n",
    "        h0 = F.relu(batch_norm(self.linear1(z)))            # 72, 1024\n",
    "        h0 = torch.cat((h0,y),1)                            # 72, 1037\n",
    "\n",
    "        h1 = F.relu(batch_norm(self.linear2(h0)))           # 72, 256\n",
    "        h1 = h1.view(batch_size, self.gf_dim * 2, 2, 1)     # 72, 128, 2, 1\n",
    "        h1 = concat_vector(h1, yb)                          # 72, 141, 2, 1\n",
    "        h1 = concat_vector(h1, h3_prev)                     # 72, 157, 2, 1\n",
    "\n",
    "        h2 = F.relu(batch_norm(self.h1(h1)))                # 72, 128, 4, 1\n",
    "        h2 = concat_vector(h2, yb)                          # 72, 141, 4, 1\n",
    "        h2 = concat_vector(h2, h2_prev)                     # 72, 157, 4, 1\n",
    "\n",
    "        h3 = F.relu(batch_norm(self.h2(h2)))                # 72, 128, 8, 1 \n",
    "        h3 = concat_vector(h3, yb)                          # 72, 141, 8, 1\n",
    "        h3 = concat_vector(h3, h1_prev)                     # 72, 157, 8, 1\n",
    "\n",
    "        h4 = F.relu(batch_norm(self.h3(h3)))                # 72, 128, 16, 1\n",
    "        h4 = concat_vector(h4, yb)                          # 72, 141, 16, 1\n",
    "        h4 = concat_vector(h4, h0_prev)                     # 72, 157, 16, 1\n",
    "\n",
    "        g_x = torch.sigmoid(self.h4(h4))                    # 72, 1, 16, 128\n",
    "\n",
    "        return g_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator\n",
    "forwardの入力\n",
    "- x (batch, 1, steps, pitch) = (72, 1, 16, 128): real/fake判定を行う小節データ\n",
    "- y (batch, 13) = (72, 13): コード\n",
    "\n",
    "forwardの出力\n",
    "- h3_sigmoid (batch, 1) = (72, 1): 0~1に押し込められたreal/fake判定結果．0はfake, 1はreal\n",
    "- h3 (batch, 1) = (72, 1): 0~1に押し込められていないreal/fake判定結果\n",
    "- fm (batch, 1+13, steps, pitch) = (72, 14, 16, 128): 特徴マップ．\n",
    "\n",
    "オリジナルのmidinetと同じ．詳しい説明はmidinet_understandingを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,pitch_range=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.df_dim = 64\n",
    "        self.dfc_dim = 1024\n",
    "        self.y_dim = 13\n",
    "        \n",
    "        # out channels = y_dim +1 \n",
    "        self.h0_prev = nn.Conv2d(in_channels=14, out_channels=14, kernel_size=(2,pitch_range), stride=(2,2))\n",
    "\n",
    "        # out channels = df_dim + y_dim\n",
    "        self.h1_prev = nn.Conv2d(in_channels=27, out_channels=77, kernel_size=(4,1), stride=(2,2))\n",
    "        self.linear1 = nn.Linear(244, self.dfc_dim)\n",
    "        self.linear2 = nn.Linear(1037, 1)\n",
    "\n",
    "    def forward(self, x, y, batch_size, pitch_range):        \n",
    "\n",
    "        yb = y.view(batch_size,self.y_dim, 1, 1)\n",
    "        x = concat_vector(x, yb)                    #72, 14, 16, 128\n",
    "        \n",
    "        h0 = lrelu(self.h0_prev(x))                 #72, 14, 8, 1\n",
    "        fm = h0\n",
    "        h0 = concat_vector(h0, yb)                  #72, 27, 8, 1\n",
    "\n",
    "        h1 = lrelu(batch_norm(self.h1_prev(h0)))    #72, 77, 3, 1\n",
    "        h1 = h1.view(batch_size, -1)                #72, 231\n",
    "        h1 = torch.cat((h1,y), 1)                   #72, 244\n",
    "\n",
    "        h2 = lrelu(batch_norm(self.linear1(h1)))\n",
    "        h2 = torch.cat((h2,y), 1)                   #72, 1037\n",
    "\n",
    "        h3 = self.linear2(h2)\n",
    "        h3_sigmoid = torch.sigmoid(h3)\n",
    "\n",
    "\n",
    "        return h3_sigmoid, h3, fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コードの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 共通関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mean(x):\n",
    "    output = torch.mean(x,0, keepdim = False)\n",
    "    output = torch.mean(output,-1, keepdim = False)\n",
    "    return output\n",
    "\n",
    "def reduce_mean_0(x):\n",
    "    output = torch.mean(x,0, keepdim = False)\n",
    "    return output\n",
    "\n",
    "def l2_loss(x,y):\n",
    "    return nn.MSELoss(reduction='sum')(x, y) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存先の指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(output_dir, \"natural\")\n",
    "\n",
    "if not os.path.isdir:\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "npsave = lambda file_name, nparray: np.save(os.path.join(save_dir, file_name), nparray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 72\n",
    "generator_train_times = 2\n",
    "sample_bar_num = 16 # あとで実装\n",
    "\n",
    "# for Adam\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "\n",
    "# noise vector size\n",
    "nz = 100\n",
    "\n",
    "# a coefficient to real label for discriminator. 0 ~ 1\n",
    "real_data_worthiness = 0.9\n",
    "\n",
    "# feature matching coefficients\n",
    "lambda_1, lambda_2 = 0.1, 0.01 # D, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習初期化処理  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading is completed.\n",
      "663 batches from 47723 bars are obtained.\n"
     ]
    }
   ],
   "source": [
    "data_loader = get_dataloader(input_file_path, batch_size=batch_size)\n",
    "data_size = len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# .to(device)でGPUメモリ確保\n",
    "netD = Discriminator().to(device)\n",
    "netG = Generator().to(device)\n",
    "\n",
    "netD.train()\n",
    "netG.train()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=betas)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=betas) \n",
    "\n",
    "noise_for_sample = torch.randn(batch_size, nz, device=device)\n",
    "\n",
    "fake_label, real_label = 0, 1\n",
    "\n",
    "avg_lossD, avg_lossG = 0, 0\n",
    "avg_D_x, avg_D_G_z = 0, 0\n",
    "\n",
    "lossD_list, lossD_list_all = [], [] # Dのエポックごとの誤差\n",
    "lossG_list, lossG_list_all = [], []\n",
    "D_x_list, D_G_z_list = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習ループ\n",
    "オリジナルのコードを若干書き換え  \n",
    "ノイズベクトルは毎回作り直すことにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    sum_lossD, sum_lossG = 0, 0\n",
    "    sum_D_x, sum_D_G_z = 0, 0\n",
    "    \n",
    "    print(f\"start epoch {epoch} / {epochs}\")\n",
    "    for i, (real, prev, chord) in enumerate(train_loader):\n",
    "\n",
    "        # バッチ(譜面，前の譜面，コード)をdeviceに渡す  \n",
    "        real, prev, chord = [item.to(device) for item in [real, prev, chord]]\n",
    "        \n",
    "        # batchの切れ端はサイズが異なる場合があるので注意\n",
    "        batch_size = real.size(0)\n",
    "\n",
    "        \n",
    "        ############################\n",
    "        # Dの学習: log(D(x)) + log(1 - D(G(z))) を最大化\n",
    "        # realデータを1，fakeデータを0と判断させるよう学習\n",
    "        ###########################\n",
    "\n",
    "        # Dのrealデータに対する訓練\n",
    "        \n",
    "        # Dの勾配の初期化\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        # realに対する識別結果からクロスエントロピー誤差(目的関数)の値を得る\n",
    "        d_real, d_logits_real, fm_real = netD(real, chord, batch_size)\n",
    "        d_real_label = real_data_worthiness * torch.ones_like(d_real)\n",
    "        d_loss_real = nn.BCEWithLogitsLoss(d_logits_real, d_real_label)\n",
    "        d_loss_real = reduce_mean(d_loss_real)\n",
    "\n",
    "        # 誤差の逆伝搬と記録\n",
    "        d_loss_real.backward(retain_graph=True)\n",
    "        D_x = d_real.mean().item() # realへのdのロス．記録しないが表示する\n",
    "        sum_D_x += D_x \n",
    "\n",
    "\n",
    "        # Dのfakeデータに対する訓練\n",
    "\n",
    "        # Gにノイズベクトル，前の譜面，コードを渡し，fakeデータを作成\n",
    "        noise = torch.randn(batch_size, nz, device=device)\n",
    "        fake = netG(noise, prev, chord, batch_size)\n",
    "\n",
    "        # fakeに対する識別結果からクロスエントロピー誤差(目的関数)の値を得る\n",
    "        d_fake, d_logits_fake, fm_fake = netD(fake.detach(), chord, batch_size)\n",
    "        d_fake_label = torch.zeros_like(d_fake)\n",
    "        d_loss_fake = nn.BCEWithLogitsLoss(d_logits_fake, d_fake_label)\n",
    "        d_loss_fake = reduce_mean()\n",
    "\n",
    "        # 誤差の逆伝搬と記録\n",
    "        d_loss_fake.backward(retain_graph=True)\n",
    "        D_G_z1 = d_fake.mean().item() # fakeへのDのロス．\n",
    "        errD = (d_loss_real + d_loss_fake).item()\n",
    "        sum_lossD += errD\n",
    "        lossD_list_all.append(errD)\n",
    "\n",
    "\n",
    "        # Dの勾配からパラメータを更新\n",
    "        optimizerD.step()\n",
    "\n",
    "\n",
    "        ############################\n",
    "        # Gの学習 : log(D(G(z)))を最大化\n",
    "        # fakeデータを1と判断させるよう学習\n",
    "        ###########################\n",
    "        \n",
    "        for t in range(generator_train_times):\n",
    "            \n",
    "            # Gの勾配の初期化\n",
    "            netG.zero_grad()\n",
    "\n",
    "            # Gにノイズベクトル，前の譜面，コードを渡し，fakeデータを作成\n",
    "            noise = torch.randn(batch_size, nz, device=device)\n",
    "            fake = netG(noise, prev, chord, batch_size)\n",
    "\n",
    "            # fakeに対して1をラベルとした識別結果からクロスエントロピー誤差(目的関数)の値を得てGの誤差とする\n",
    "            d_fake, d_logits_fake, fm_fake = netD(fake, chord, batch_size)\n",
    "            deceive_label = torch.ones_like(d_fake)\n",
    "            g_loss = nn.BCEWithLogitsLoss(d_logits_fake, deceive_label)\n",
    "            g_loss = reduce_mean(g_loss0)\n",
    "\n",
    "            # Dの特徴マッチング：realとfakeでnetDの初段のreluの出力が近くなるようにする\n",
    "            features_from_g = reduce_mean_0(fm_fake) # fakeデータに対するDのfeatureの平均値\n",
    "            features_from_i = reduce_mean_0(fm_real) # realデータに対するDのfeatureの平均値\n",
    "            # fakeとrealの出すfeatureの違いが大きいほどペナルティを与える\n",
    "            fm_g_loss1 =torch.mul(l2_loss(features_from_g, features_from_i), lambda_1)\n",
    "\n",
    "            # Gの特徴マッチング：Gがrealに近いデータを生成できるようにする\n",
    "            mean_image_from_g = reduce_mean_0(fake) # fakeデータの平均値\n",
    "            mean_image_from_i = reduce_mean_0(real) # realデータの平均値\n",
    "            # fakeデータとrealデータの違いが大きいほどペナルティを与える\n",
    "            fm_g_loss2 = torch.mul(l2_loss(mean_image_from_g, mean_image_from_i), lambda_2)\n",
    "\n",
    "            # 誤差の逆伝搬と記録\n",
    "            errG = g_loss + fm_g_loss1 + fm_g_loss2\n",
    "            errG.backward(retain_graph=(t >= generator_train_times - 1)) # 最後は計算グラフを放棄\n",
    "\n",
    "            # Gの勾配からパラメータを更新\n",
    "            optimizerG.step()\n",
    "\n",
    "        # Gの最後のロスを記録\n",
    "        lossG_list_all.append(errG.item())\n",
    "        sum_D_G_z += d_fake.mean().item() # fakeへのDのロス．\n",
    "    \n",
    "\n",
    "    # エポックごとの誤差の記録\n",
    "    avg_lossD, avg_lossG = sum_lossD / data_size, sum_lossG / data_size\n",
    "    avg_D_x, avg_D_G_z = sum_D_x / data_size, sum_D_G_z / data_size\n",
    "\n",
    "    lossD_list.append(avg_lossD)\n",
    "    lossG_list.append(avg_lossG)\n",
    "    D_x_list.append(avg_D_x)\n",
    "    D_G_z_list.append(avg_D_G_z)\n",
    "\n",
    "    print(f'==> avg_lossD: {avg_lossD:.4f} avg_lossG: {avg_lossG:.4f}, avg_D(x): {avg_D_x:.4f},avg D(G(z)): {avg_D_G_z:.4f} ')\n",
    "    \n",
    "    # 5エポックごとに具体的なロスの状況を報告し，生成データを画像で記録\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'[epoch {epoch}] Loss_D: {errD:.4f} Loss_G: {errG:.4f} D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "        fake_file_name = f'fake_samples_epoch{epoch:03}.png'\n",
    "        sample_fake = netG(noise_for_sample, prev, chord, batch_size)\n",
    "        vutils.save_image(sample_fake.detach(), os.path.join(save_dir, fake_file_name), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記録とモデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npsave('lossD_list.npy',lossD_list)\n",
    "npsave('lossG_list.npy',lossG_list)\n",
    "npsave('lossD_list_all.npy',lossD_list_all)\n",
    "npsave('lossG_list_all.npy',lossG_list_all)\n",
    "npsave('D_x_list.npy',D_x_list)\n",
    "npsave('D_G_z_list.npy',D_G_z_list)\n",
    "torch.save(netG.state_dict(), os.path.join(output_dir, f'netG_epoch_{epoch}.pth'))\n",
    "torch.save(netD.state_dict(), os.path.join(output_dir, f'netD_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機能2. 誤差のグラフを作成する\n",
    "if is_draw == 1:\n",
    "    lossD_print = np.load('lossD_list.npy')\n",
    "    lossG_print = np.load('lossG_list.npy')\n",
    "    length = lossG_print.shape[0]\n",
    "\n",
    "    x = np.linspace(0, length-1, length)\n",
    "    x = np.asarray(x)\n",
    "    plt.figure()\n",
    "    plt.plot(x, lossD_print,label=' lossD',linewidth=1.5)\n",
    "    plt.plot(x, lossG_print,label=' lossG',linewidth=1.5)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('data')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig('where you want to save/lr='+ str(lr) +'_epoch='+str(epochs)+'.png')\n",
    "\n",
    "\n",
    "\n",
    "# 機能3. サンプルを作成する\n",
    "if is_sample == 1:\n",
    "    batch_size = 8\n",
    "    nz = 100\n",
    "    n_bars = 7\n",
    "\n",
    "    # データの取得\n",
    "    X_te = np.load('your testing x') # 最初の小節\n",
    "    prev_X_te = np.load('your testing prev x') # 前の小節\n",
    "    prev_X_te = prev_X_te[:,:,check_range_st:check_range_ed,:]\n",
    "    y_te    = np.load('yourd chord') # コード\n",
    "\n",
    "    # DataLoaderの準備\n",
    "    test_iter = get_dataloader(X_te,prev_X_te,y_te)\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True}# if args.cuda else {}\n",
    "    test_loader = DataLoader(test_iter, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    # サンプル生成用のGを用意し，訓練済みパラメータを読み込ませる\n",
    "    netG = sample_generator()\n",
    "    netG.load_state_dict(torch.load('your model'))\n",
    "\n",
    "    # サンプルの生成ループ\n",
    "    output_songs = []\n",
    "    output_chords = []\n",
    "    for i, (data,prev_data,chord) in enumerate(test_loader, 0):\n",
    "        list_song = []\n",
    "        first_bar = data[0].view(1,1,16,128)\n",
    "        list_song.append(first_bar)\n",
    "\n",
    "        list_chord = []\n",
    "        first_chord = chord[0].view(1,13).numpy()\n",
    "        list_chord.append(first_chord)\n",
    "        noise = torch.randn(batch_size, nz)\n",
    "\n",
    "        # 小節生成ループ\n",
    "        for bar in range(n_bars):\n",
    "            z = noise[bar].view(1,nz)\n",
    "            y = chord[bar].view(1,13)\n",
    "\n",
    "            if bar == 0:\n",
    "                # 最初の小節はrealデータを使う\n",
    "                prev = data[0].view(1,1,16,128)\n",
    "            else:\n",
    "                # 2小節目からは前の小節を条件にする\n",
    "                prev = list_song[bar-1].view(1,1,16,128)\n",
    "\n",
    "            # ランダムノイズを基に，前の小節と今のコードを条件として渡して，今の小節を生成\n",
    "            sample = netG(z, prev, y, 1,pitch_range)\n",
    "\n",
    "            # 小節を記録\n",
    "            list_song.append(sample)\n",
    "            list_chord.append(y.numpy())\n",
    "\n",
    "        # 生成された曲を記録\n",
    "        print('num of output_songs: {}'.format(len(output_songs)))\n",
    "        output_songs.append(list_song)\n",
    "        output_chords.append(list_chord)\n",
    "\n",
    "    # 生成された曲の保存\n",
    "    np.save('output_songs.npy',np.asarray(output_songs))\n",
    "    np.save('output_chords.npy',np.asarray(output_chords))\n",
    "\n",
    "    print('creation completed, check out what I make!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
